#1-oct 

> [!definition] Conditional distribution
> $X$ , $Y$ discrete RV the conditional pmf of $X$ given $Y=y$ 
> $P_{X|Y}(x|y)=P(X=x|Y=y)=\frac{p(x,y)}{P_{Y}(y)}$ only when $P_{Y}(y)>0$

> [!remark] 
> $\large{ \sum_{x}^{}P_{X|Y}(x|y)=1}$ 

$$
\begin{align}
	\sum_{x}^{}P_{X|Y}(x|y) & =\frac{1}{P(Y=y)}\sum_{x}^{}P(X=x,Y=y) \\
 & =\frac{1}{P(Y=y)}P(Y=y) \\
 & =1 \\
\end{align}
$$
$$
\begin{align}
P_{X|Y}(x|y)=P_{X|Y=y} (x)
\end{align}
$$
> [!definition] Conditional Cumulative Distribution function 
> $X$ , $Y$ discrete RV the conditional (cumulative ) distribution function (conditional CDF) 
> of $X$ given $Y=y$ 

$$
\begin{align}
F_{X|Y} (x|y)\equiv F_{X|Y=y}(x)=P(X\leq X|Y=y) 
\end{align}
$$

If $X$ , $Y$ are independent
$$
\begin{align}
P_{X|Y=y}(x)=P_{X} (x) \\
F_{X|Y=y}(x)=F_{X}(x) \\
 \\

\end{align}
$$
## Example 

>[!important]  
> Refer `6.4 Conditional Distribution: Discrete Case`  from `A first course in Probability by` - `Sheldon Ross` (page number: 248) [[Probability/sheldon_ross.pdf#page=257|Conditional Distributions]]
> Example 4a 4b  4c 4d (Basically all the examples ) which were done in class but not completely written in this notes. Don't worry they are about the same

1. If pmf of $X$ and $Y$ 

$$
\begin{align}
p(0,0) & =0.4 \\
p(0,1) & =0.2 \\
p(1,0) & =0.1 \\
p(1,1) & =0.3 \\

\end{align}
$$
find $P_{X|Y}(X|1)=\frac{P(0,1)}{p(0,1)+p(1,1)}=\frac{2}{5}$

2. $X$ is [[Poisson]]($\lambda_{1}$) $Y$ is [[Poisson]]($\lambda_{2}$)
conditional distribution of $X$ given X+ $Y=n$ 

$$
\begin{align}
P(X=K|X+Y=n) & =\frac{P(X=K,X+Y=n)}{P(X+Y=n)} \\ \\

 & =\huge{\frac{\cfrac{e^{ -\lambda_{1} } \lambda_{1} ^{k} }{k!} \cfrac{e^{ -\lambda_{2} } \lambda_{2} ^{n-k} }{(n-k)!} }{\cfrac{e^{ -(\lambda_{1}+ \lambda_2)} (\lambda_{1}+\lambda_{2}) ^{n} }{n!} } }\\
 & = \binom{n }{k}\left( \frac{\lambda_{1}}{\lambda_{1}+\lambda_{2} } \right)^{k}\left( \frac{\lambda_{2}}{\lambda_{1}+\lambda_{2} } \right)^{n-k}
\end{align}
$$

#4-oct
3. $K$ possible outcome with probability $p_{i} \quad i=1,2,3,4\dots$ $n$ [[Probability/2. Covariance#^343121|independent]] trials 
$$
\begin{align}
P(X_{i}=n_{i}, i=1,2,3\dots )=\frac{n!}{n_{1}!n_{2}!\dots n_{k}! } p_{1}^{n_{1}}p_{2}^{n_{2}}\dots p_{k}^{n_{k} } 
\end{align}
$$
suppose given 
$$
\begin{align}
X_{j} & =n_{j} \quad j=r+1,\dots k \\
\sum_{r+1}^{K} X_{i} & =m\leq n
\end{align}
$$



$$
\begin{align}
 p(X_{1}=n_{1} & ,X_{2}=n_{2}\dots X_{r}=n_{r} |X_{r+1}=n_{r+1}\dots X_{k}=n_{k} \\
 & =\frac{p(X_{i}=n_{i } \quad i=1,2\dots k)}{P(X_{r+i}=n_{i+r} \quad i=1\dots k-r )} \\ \\
 \\
 \\
\text{ denominator } & =\binom{n }{n_{r+1},n_{r+2} \dots n_{k},(n-n_{r+1}\dots-n_{k} ) } p_{r+1}^{n_{r+1} } \dots p_{k}^{n_{k} }(1-(p_{r-1}+\dots +p_{k} )) ^{n-m} \\ \\
 \\

 p(X_{i}=n_{i} \quad i=1,2,3\dots r)& \huge{ =\frac{\frac{n!}{n_{1}!\dots n_{k}! }p_{1}^{n_{1}} \dots p_{k}^{n_{k} } }{\binom{n }{n_{r+1},n_{r+2} \dots n_{k},(n-n_{r+1}\dots-n_{k} ) } p_{r+1}^{n_{r+1} } \dots p_{k}^{n_{k} }(1-(p_{r-1}+\dots +p_{k} )) ^{n-m} } } \\ \\
 \\

 &\huge{ = \frac{(n-m)!}{n_{1}!\dots n_{r}! }p_{1}^{1}\dots p_{r}^{n_{r} } }
 
\end{align}
$$
