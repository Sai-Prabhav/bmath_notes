#20-sep 
> [!definition ] Covariance
> The Covariance between $X$ and $Y$ is $$\text{Cov}(X,Y)=E\left[ \left( X-E[X] \right) \left( Y-E[Y] \right)   \right] $$

$$
\begin{align}
\text{Cov}(X,Y) & =E\left[ \left( X-E[X] \right) \left( Y-E[Y] \right)   \right] \\
 & =E\left[ XY-XE[Y]-YE[X] +E[X][Y] \right]  \\
 & =E[XY]-E[Y]E[X]-E[X]E[Y]+E[X][Y] \\
 & =E[XY]-E[X]E[Y]
\end{align}
$$
> [!remark ] 
> If $X,Y$ is independent$\implies \text{Cov}(X,Y)=E[XY]-E[X]E[Y]=E[X]E[Y]-E[X]E[Y]=0$  
>The converse may not be true

> [!Exercise] 
>(i) $\text{Cov}(X,Y)=\text{Cov}(Y,X)$
>(ii) $\text{Cov}(X,X)= \text{Var}(X)$
>(iii) $\text{Cov}(aX,Y)=a\text{Cov}(X,Y)$
>(iv) $$\text{Cov}\left( \sum^{n}_{i=1} X_{i}, \sum^{m}_{j=1} Y_{j}\right)=\sum^{n}_{i=1}\sum^{m}_{j=1}\text{Cov}(X_{i},Y_{j})$$
>

`\begin{proof}`
(i)
(ii)
(iii)
$$
\begin{align}
E[aX] & =aE[X] \\
\text{Cov}(aX,Y) & =E[aXY]-E[aX]E[Y] \\
 & =a\left( E[XY]-E[X]E[Y] \right)  \\
 & =a\text{Cov}(X,Y)
\end{align}
$$
(iv) let
$$
\begin{align}
E[X_{i}] & =\mu_{i} \\
E[Y_{i}] & =v_{i} \\
E\left[ \sum X_{i} \right] & = \sum \mu_{i} \\
E\left[ \sum Y_{i} \right] & = \sum v_{i} \\
\text{Cov}\left( \sum^{n}_{i=1} X_{i}, \sum^{m}_{j=1} Y_{j}\right) & =E\left[ \left\{  \sum_{i}(X_{i}-\mu_{i}) \right\} \left\{  \sum_{j}(Y_{j}-v_{j}) \right\} \right] \\
 & =\sum_{i}\sum_{j}E\left[ \left( X_{i}-\mu_{i}  \right)\left( Y_{i}-v_{i} \right)   \right]  \\
 & =\sum^{n}_{i=1}\sum^{m}_{j=1}\text{Cov}(X_{i},Y_{j})
\end{align}
$$

#24-sep 

> [!definition] Sample mean and Sample Variance
$$
\begin{align}
\text{Sample mean } &  = \bar{X} = \frac{1}{n}\sum_{i=1}^{n} X_{i}  \\
\text{Sample Variance} & =S^{2} =\frac{1}{n-1}\sum_{i=1}^{n} \left( X_{i}-\bar{X}  \right) ^{2}  \\
\end{align}
$$


---
>[!definition] Independence of Random Variable 
>let $X_{1},X_{2},\dots X_{n}$ are random variable they are independent if 
$$
\begin{align}
P(X_{1}=x_{1}\dots X_{n}=x_{n}  ) =\prod^{n}_{i=1} P  (X_{i}=x_{i}  )  
\end{align}
$$

---
>[!definition] identical Random Variable 
>let $X_{1},X_{2},\dots X_{n}$ are random variable they are Identical if 
$P(X_{i}=x_{k})=P(X_{j}=x_{k}) \ \forall \ j,k,i$

---
let $X_{1},X_{2},\dots X_{n}$ are independent and identically distributed random variable 
let 
$$
\begin{align}


EX_{i}=\mu \ \forall \ i \\
\mathrm{Var} \left[ X_{i}  \right] =\sigma^{2}  \ \forall \ i \\

\end{align}
$$
lets find $\mathrm{E} \left[ \bar{X} \right]$ and $\mathrm{Var} \left[ \bar{X} \right]$ 
$$
\begin{align}

E[\bar{X}] & =\frac{1}{n}\sum_{i=1}^{n} E[X_{i} ]=\mu \\
		\mathrm{Var} \left[ \bar{X} \right] &  =\mathrm{Var} \left[ \frac{1}{n}\sum_{i=1}^{n} X_{i}  \right]  \\
 & =\frac{1}{n^{2} }\sum_{i=1}^{n}  \mathrm{Var} \left[ X_{i}  \right]  \\
 & =\frac{\sigma^{2}}{n}
\end{align}
$$
Find $\mathrm{E} \left[ S^{2} \right]$ ($S^{2}$ is the sample variance ) 
$$
\begin{align}
			E\left[ S^{2}  \right]  & =E\left[ \frac{1}{n-1}\sum_{i=1}^{n} \left( X_{i} -\bar{X}  \right)^{2}   \right]  \\ \\

 & =\frac{1}{n-1}\sum_{i=1}^{n} E\left[ \left( X_{i}-\bar{X}  \right)^{2} \right] \\
 & =\frac{1}{n-1}\sum_{i=1}^{n} E\left[  X_{i}^{2} +\bar{X}^{2} -2X_{i}\bar{X}   \right]  \\
\text{we know } E\left[ X_{i}^{2}  \right]  & =\sigma^{2} +\mu^{2}   \\
\end{align}
$$
Lets separately find  $\mathrm{E} \left[ \bar{X} X_{i}\right]$ and $\mathrm{E} \left[ \bar{X}^{2} \right]$ 
$$
\begin{align}

E\left[ X_{i}\bar{X}  \right]  & =E\left[ X_{i}\left[ \frac{X_{1}+X_{2}\dots X_{n} }{n} \right]   \right]  \\
		 & = \frac{1}{n}\sum_{j=1}^{n} E\left[ X_{i}X_{j}   \right]  \\
	 & =\frac{1}{n}\left( E\left[ X_{i}^{2} \right]+\sum_{i\neq i}^{}   E[X_{i} ]E[X_{j} ]  \right)  \\
	 & =\frac{1}{n}\left[ \sigma^{2} +\mu^{2} +(n-1)\mu^{2}  \right]  \\
	 & =\frac{1}{n}\left[ \sigma^{2}  +n\mu^{2}  \right]  \\
 
\end{align}
$$
---
$$
\begin{align}
  E\left[ \frac{X_{1}+X_{2}\dots X_{n}}{n}\cdot\frac{X_{1}+X_{2}\dots X_{n}}{n} \right] 
 & =\frac{1}{n^{2} }\sum_{i=1}^{n} \sum_{i=1}^{n} E\left[ X_{i}  X_{j}  \right]  \\
& =\frac{1}{n^{2} } \left[ \sum_{i}^{} E\left[ X_{i} ^{2}  \right]  + \sum_{i<j} \mathrm{E} \left[ X_{i} X_{j}  \right] \right]  \\
& =\frac{1}{n^{2} } \left[ n(\sigma^{2} +\mu^{2} ) + \sum_{i<j} \mathrm{E} \left[ X_{i}\right]  \mathrm{E} \left[ X_{j} \right] \right] \\

\end{align}
$$
---

Basically fuck the above as its too lengthy and do it in a better way
$$
\begin{align}
	\mathrm{Var} \left[ \bar{X} \right]  & =\mathrm{E} \left[ \bar{X}^{2}  \right]  -\left\{ \mathrm{E} \left[ \bar{X} \right]  \right\} ^{2}  \\
		\implies \mathrm{E} \left[ \bar{X} ^{2} \right]  &=\mathrm{Var} \left[ \bar{X} \right] + \left( \mathrm{E} \left[ \bar{X} \right]  \right) ^{2} \\
 &=\frac{\sigma^{2}}{n}  + \mu^{2} 
\end{align}
$$
$$
\begin{align}
\mathrm{E} \left[ S^{2}  \right]  & =\frac{1}{n-1}\sum_{i=1}^{n} E\left[  X_{i}^{2} +\bar{X}^{2} -2X_{i}\bar{X}   \right]   \\
 & =\frac{1}{n-1} n\left\{ \sigma^{2} +\mu^{2} +\frac{\sigma^{2}}{n}+\mu^{2} -\frac{2\sigma^{2}}{n}-2\mu^{2} \right\} \\
 & =\frac{1}{n-1} n\left\{ \sigma^{2}  -\frac{\sigma^{2}}{n}\right\} \\
 & =\frac{1}{n-1} \left\{ n\sigma^{2}  -{\sigma^{2}}{}\right\} \\
 & =\frac{1}{n-1} \left\{ n  -1\right\} \cdot \sigma^{2}  \\
 & =\sigma^{2}  \\

\end{align}
$$

`\end{proof}`

<div class="math math-block is-loaded" ></div>



> [!example] Sampling from finite population 
> Polulation of $N$ people voting in election $A$ is a candiditte for election

for each person $i$ in population

$$
\begin{align}
\nu_{i}=\begin{cases}
1 \text{ if person will vote for  } A  \\
0 \text{ otherwise }
\end{cases} 
\end{align}
$$
$$
\begin{align}
	V=\frac{\sum_{i=1}^{N} \nu_{i} }{N}
\end{align}
$$
Proportion in favor of $A$ 
Take sample of size $n$ from population.
Take average of $\mu_{i}$ for sample is estimator for V
$$
\begin{align}
I_{i}=\begin{cases}
1 \text{ if a person $i$ in sample }\\
0 \text{if prson not in sample}
\end{cases} 
\end{align}
$$

let $S$ be the number of people in flavor of $A$ in the sample 
$$
\frac{S}{n}=\frac{1}{n}\sum_{i=1}^{N} \nu_{1} I_{i} 
$$
is the proportion of people in sample who favor $A$ 
$$
\begin{align}
			\mathrm{E} \left[ \frac{S}{n} \right]  & =\frac{1}{n}\sum_{i=1}^{n} \nu_{i} \mathrm{E} \left[ I_{i}  \right]  \\
	\mathrm{E} \left[ I_{i}  \right]  & =\frac{n}{N}
\end{align}
$$
$$
\begin{align}
				\mathrm{E} \left[ \frac{S}{n} \right]  & =\frac{1}{n}\sum_{i=1}^{n} \nu_{i} \frac{n}{N}=V  \\
& =\sum_{i=1}^{n} \frac{\nu_{i} }{N}=V
\end{align}
$$
(question::conform the above stuff)

$$
\begin{align}
		\mathrm{Var} \left[ \frac{S}{n} \right]  & =\frac{1}{n^{2} }  \mathrm{Var} \left[ \sum_{i=1}^{N} \nu_{i} I_{i}  \right]\\
		 & =\frac{1}{n^{2} }\left( \sum_{i=1}^{N} \mathrm{Var} \left[ \nu_{i} I_{i}  \right]  +2\sum_{1\leq i< j\leq N}\mathrm{Cov} \left( \nu_{i} I_{i} ,\nu_{j}I_{j}   \right)  \right)  \\
				 & = \frac{1}{n^{2} }\left[ \sum_{i=1}^{N} \nu_{i}^{2} \mathrm{Var} \left[ I_{i}  \right] +2\sum_{i<j}\nu_{i} \nu_{j} \mathrm{ Cov} \left( I_{i} ,I_{j}  \right)    \right] 
\end{align}
$$
(question:: how the second step happen)

$$
\begin{align}
\mathrm{Var} \left[ I_{i}  \right] &   =\mathrm{E} \left[ I_{i} ^{2}  \right] -\left(E [I_{i} ] \right) ^{2}  \\
		 & =E[I_{i} ]-\left( E[I_{i} ] \right) ^{2}  \\
			 & =\frac{n }{N } -\left[ \frac{n}{N} \right] ^{2} 
\end{align}
$$
$$
\begin{align}
\mathrm{ Cov} \left( I_{i} ,I_{j}  \right) &  =\mathrm{E} \left[ I_{i} I_{j}  \right] -\mathrm{E} \left[ I_{i}  \right] \mathrm{E} \left[ I_{j}  \right]  \\
	 & =\frac{\binom{N-2}{n-2}}{\binom{N }{n}}-\left[ \frac{n}{N} \right] ^{2}  \\
	 & =\frac{n(n-1)}{N(N-1)}-\left[ \frac{n}{N} \right] ^{2}  \\

\end{align}
$$
$$
\begin{align}
\sum_{i\neq j}^{} \nu_{i} \nu_{j}  & = \sum_{i}^{} \sum_{i\neq j}^{ } \nu_{i}\nu_{j}   \\
& =\sum_{i}^{ } \nu_{i} \left( \sum_{j}^{} \nu_{j} -\nu_{i}  \right) \\
& =n^{2} V^{2} -\sum_{i=1}^{N} \nu_{i} ^{2} \\
& =n^{2} V^{2} -\sum_{i=1}^{N} \nu_{i}\\
\end{align}
$$

$$
\begin{align}
\mathrm{Var} \left[ \frac{S}{n} \right]  & =\frac{N-n}{n(N-1)}\left( \frac{\sum_{}^{} \nu_{i} ^{2} }{N}-V \right)  \\
&= \frac{N-n}{n(N-1)}\left[ V-V^{2}  \right] 
\end{align}
$$
