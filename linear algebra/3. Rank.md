#24-sep 
Rank of a matrix Let $A$ be a $m\times n$ matrix,
column space of $A$ is the subspace of $\mathbb{R}^{m}$ spanned by the columns of $A$ 
if $A_{1},A_{2},A_{3}\dots A_{n}$ are the columns of $A$ and $A_{i}$ is in $\mathbb{R}^{m}$ then,
column space of $A=\{ c_{1}A_{1}+c_{2}a_{2}\dots+c_{n}A_{n};c_{i}\in \mathbb{R} \}$

so, column space of $A$ is all $(\alpha_{1},\dots\alpha_{n})\in \mathbb{R}^{n}$ such that 
$$
\begin{align}
A(x_{1},\dots x_{n} )^{t}=(\alpha_{1},\dots\alpha_{n} )^{t}  
\end{align}
$$
has a solution.

In terms of liner transformation defined by the linear matrix $A$ 
$T_{A}:\mathbb{R}^{n}\to \mathbb{R}^{m}$
$X\mapsto AX$


Column rank of $A$ is the dimension of the column space of $A$ 
Row rank of $A$ is the dimension of the row space of $A$ 

> [!theorem]
For a $m\times n$ matrix $A$ the row rank is same as the column space  of $A$ and is called the rank of $A$ 

# Rank of product of matrices 
Let $r(A)$ denote the rank of $A$ 
Let us try to find an upper bound for $r(AB)$ 
> [!theorem] 
> Let $A$ and $B$  be matrices with same number of rows 
> Then, column space $B$ $\subseteq$ column space of $A$ iff $B=AC$ for some matrix C

^8cc1ad

 Let $B=AC$ 
 Let $X \ \in$ columns space of $B$ 
 Let $X=BY\implies X=ACY= A(CY)=AY'\implies X\in$ column space of $A$
Conversely assume column space $B$ $\subseteq$ column space of $C$ 
In particular every column of $B$ lies in the column space of $A$ .
Which implies every column of $B$ can be written as the linear combination of the columns of $A$ 
So if $B_{1},\dots B_{n}$ are the column vectors of $B$ then there exist scalars $c_{ij},1\leq i\leq p$ 
$B_{j}=A_{1}c_{1j}\dots A_{p}c_{pj}$
Let $C=\left( c_{ij} \right)$ and $B=AC$

> [!theorem] 
> Let $A$ , $B$ be matrices with same number of columns then the row space of $B$ $\subseteq$ row space of A iff $B=DA$ for a matrix $D$ 
(todo::complete it)

^72e467

> [!definition] let $A$  be a $m\times n$ matrix $A$ is said to be of full column rank if 
> $r(A)=n$ and is said to be full row rank is $r(A)=m$  

> [!lemma] 
> if $A$ have full column rank, then $A$ has a left inverse, ie, $\exists$ a $C_{n\times m}$ such that $CA=I_{n}$

$A$ has a full column rank, the columns of $A$ are linear independent  

#26-sep

---
> [!theorem] 
> Let $A$ be a $m\times n$ matrix. Then the following are equivalent 
> i) $A$ has a right inverse
> ii) $X^{t}A=Y^{t}A\implies X=Y$
> iii) $X^{t}A=0\implies X=0$
>iv) $r(a)=m$ ie, $A$ is a full row rank
> V) column space of A is $\mathbb{R}^{m}$


`\begin{proof}`
$i$ $\implies$ ii
If $A$ has a right inverse such that $AB=I_{n}$
if 
$$
\begin{align}
		X^{t} A & =Y^{t}A  \\
	X^{t}AB & =Y^{t}  AB  \\
	\implies X^{t}  & =y^{t} 
\end{align}
$$
ii) $\implies$iii)
clear 
iii) => iv)

let the rows of $A$ be $R_{1},\dots R_{m}$ 
$$
\begin{align}
	c_{1}R_{1}+c_{2}R_{2}\dots c_{m} R_{m}=O_{m\times1}  
\end{align}
$$
$$
\begin{align}
\implies (c_{1}\ c_{2} \ \dots c_{m} )A=O_{n\times 1} 
\end{align}
$$
by iii) $(c_{1},c_{2}c_{3},\dots c_{n})=O$ 
$\implies$ the rows are linear independent
iv)$\implies$v)
$A:\mathbb{R}^{n}\to \mathbb{R}^{m}$
$\implies X\mapsto AX$ 
column space of $A \subseteq \mathbb{R}^{m}$
	But $m=r(A)=\text{dim column space} \leq\dim \mathbb{R}^{m}=m$ 
$\implies\text{column space }=\mathbb{R}^{m}$
V)$\implies$i)

Col space of A $= \mathbb{R}^{m}$
let $e_{1},e_{2},\dots e_{m}$ be the unit vectors in $\mathbb{R}^{m}$

as columns space $A=\mathbb{R}^{m}$  each $e_{j}$ is a linear combination of columns in $A$:
so there exist scalars $c_{ij},i\leq j\leq m,i\leq i\leq n$ such that 
$$
\begin{align}
e_{j} & =A_{1}c_{1j}+A_{2}c_{2j}\dots+A_{n}c_{nj} \\
		 & =A \begin{bmatrix}c_{1j}  \\ c_{2j}  \\ \vdots \\ c_{nj} \end{bmatrix}  \\
 & = A(C_{j}  )_{n\times 1} 
\end{align}
$$
so, $(e_{1},e_{2}\dots e_{m})=A(C_{1} C_{2}\dots C_{m})$
$\implies I_{m}=AC\text{ where } c=(c_{ij})$ 

> [!theorem] 
>Let $A$ be a $m\times n$ matrix. The following are equvalent 
>i) $A$ has a left inverse
>ii) $AX=AY\implies X=Y$
> iii) $AX=0\implies X=0$
>iv) $r(A)=n$ ie, A has full column rank
>row space of $\mathbb{R}^{M}$

iii)$\implies$iv)
let the columns be $A_{1},A_{2}\dots A_{n}$
let $A_{1}x_{1}+\dots A_{n}x_{n}=-o_{m\times1}$ be a linear relation
$$
\begin{align}
		\implies AX=O_{m\times_{1}}  \text{ where } X=(x_{1},x_{2},x_{3}\dots x_{n} )^{t}  \\

\end{align}
$$
iii) $\implies X=O$ that is $X_{1}=X_{2}=\dots X_{n}=0$

iv) $\implies$ V) 
$$
\begin{align}
	n=r(A) & =\dim(\text{row space } A) \\
		\text{row space}(A) & \subseteq \mathbb{R}^{N}  \\
\text{dimension row space} (A) & \leq n \\
\text{combining, row space}(A) & =\mathbb{R}^{n} 
\end{align}
$$
v) $\implies$i)
As row space $A=\mathbb{R}^{n}$ each of the basis vectors $e_{1},e_{2}\dots e_{n}$ of $\mathbb{R}^{n}$ in a linear combination of the rows of A let the rows be $R_{1}\dots R_{m}$. So, there exist scalars $b_{1j}R_{1}\dots b_{jm}R_{m} \forall \ 1\leq j\leq n$ 
Take $B=(b_{ij})$ and $BA=I_{n}$

> [!theorem] 
> Let $A$ a square matrix of order A TFAE
> i) A has a right inverse
> ii)$r(A)=n$
> iii) A has a left inverse 
> iv) A has an inverse

 

> [!theorem] 
$r(AB)\leq  min\left\{ r(A),r(B^{}) \right\}$


`\begin{proof}`
by [[#^8cc1ad]] $\text{column space }(AB\subseteq\text{ column space }(A)\implies r(AB)\leq r(B)$
also by [[#^72e467]] $\text{row space }(AB)\subseteq\text{row space of }(B)\implies r(AB)\leq r(A)$
thus $r(AB)\leq min\left\{ r(A),r(B) \right\}$ 
`\end{proof}`
> [!corollary] 
> $r(AB)=r(B)$ if $A$ is of full column rank 

`\begin{proof}`
$A$ has a left inverse say $C$ 
$$
\begin{align}
r(B)=r(CAB)\leq r(AB)  \\
\text{so } r(AB)=r(B)
\end{align}
$$
ii) $r(AB)=r(A)$ if $B$ is a full row rank
`\end{proof}`

> [!exercise] 
> A is a matrix of rank 1 iff $A=VU^{T}, V,U\neq0$ where $V$ and $U$ are column vectors 


`\begin{proof}`
If $A=VU^{T}$ then rank $A=1$ as $r(A)\leq1$ and $r(A)\neq0$ as $V,U\neq0$

Conversely let $r(A)=1$ 
That is, the dimension of column space $A = 1= \left< v \right>$
$$
\begin{align}
\implies AX & =\lambda_{x}  v\ \forall  \ X\in \mathbb{R}^{n}, \lambda_{x} \in \mathbb{R}  \\
\implies A_{1} & =v\lambda_{1} \text{where }A_{i} \text{ is ith column of } A\\
\vdots & =\vdots \\

\implies A_{i} & =v\lambda_{i}  \\
\implies A=[\lambda_{1}\mathbf{v}\dots\lambda_{n}v ] & =v_{m\times1} (\lambda_{1}\dots\lambda n ) \\
\end{align}
$$

#1-oct

Let ${\cal C} (A)$ denote the column space
${\cal R}(A)$ denote row space 
${\cal N}(A)$ denote the null space of A

> [!theorem] 
> Let  $B$  be an $n\times p$ matrix over  $F$  and  $T$  be a subspace of $F^{P}$  $F$  is a field let $S=\left\{ BX:X\in T \right\}$ $B:F^{P}\to F^{N}$ $X\mapsto BX$ 
> Let  $W$  be null space of  $B$  $\subseteq F^{p}$  then  $S$  is a subspace of $F^{n}$ and 
> Then $\dim S+ \dim W\cap T=\dim T$ 

^5e5b72


`\begin{proof}`
 $\Res[B]{T}:T\to S$ 
 $\text{im } \Res[B]{T}=S, \ker \Res[B]{T}=\ker B\cap T=W\cap T$ 
 [[Rank Nullity]] for $\Res[B]{T}$ says that $\dim S+ \dim W\cap T=\dim T$
`\end{proof}`

> [!theorem] 
> If $AB$ is defined, then 
> $r(AB)=r(B)-\dim(\mathcal{C}(B)\cap \mathcal{N}(A))$ 


`\begin{proof}`
$A_{m\times p}\ B_{p\times n}\ AB_{m\times n}$
$$
\begin{align}
\dim\left\{ \mathcal{C}(B)\cap \mathcal{N}(A) \right\} & =\left\{ BX:ABX=0 \right\} \\
 & =\dim \left\{ BX:X\in \mathcal{N}(AB) \right\}\\
	\text{Let } S & =\left\{ BX:X\in \mathcal{N}(AB) \right\} \\
\text{and } T & =\mathcal{N}(AB) \\
\dim S &  = \dim(\mathcal{N}(AB))-\dim(\mathcal{N}(AB)\cap \mathcal{N}B)\\
\text{Now, } \mathcal{N}(B) & \subseteq \mathcal{N}(AB)  \\

\implies \dim S  & = \dim (\mathcal{N}(AB))-\dim(\mathcal{N}(B)) \\
 & = (n-r(AB))-(n-r(B))  \\
 & =r(B)-r(AB) \\
r(AB) & =r(B)-\dim(\mathcal{C}(B)\cap \mathcal{N}(A))
\end{align}
$$





`\end{proof}`

> [!theorem] Sylvester's inequality
>Let $A,B$ be matrices of order $m\times n$  and $n\times p$ , 
> then  $r(AB)\geq r(A)+r(b)-n$ 
> the equality holds iff $\mathcal{N}(A)\subseteq \mathcal{C}(B)$ 

`\begin{proof}`

$$
\begin{align} 
 \mathcal{N}(A)& \subseteq (revers) \mathcal{C}(B)\cap \mathcal{N}(A)   \\
r(AB) & =r(B)-\dim(\mathcal{C}(B)\cap \mathcal{N}(A)) \\
 & \geq r(B)-\dim\mathcal{N}(A) \\
 & =r(b)-(n-\dim\mathcal{C}(A)) \\
 & = r(b)-n+r(A) \\
 & \text{Equvality holds iff} \\
\dim \mathcal{N}(A) & =\dim(\mathcal{C}(B) \cap \mathcal{N}(A)) \\
\text{Equivalently ,}\mathcal{N}(A) & \subseteq \mathcal{C}(B)
\end{align}
$$
`\end{proof}`
## Rank Factorization of Matrix


> [!definition] Rank Factorization of Matrix
Let $A$ be a $m\times n$ matrix of rank  $r$  . $A$ Rank factorization of $A$ is a pair of matrices $(P,Q)$ where  $P$  is  of order $m\times r$ and $Q$ is of order $r\times n$, such that $A=PQ$ 

> [!theorem] 
> Let $A=PQ$  $P$  is $m\times k$ and $Q$ be $k\times n$ then $r(A)\leq k$ also, TFAE
> i)k=r(A),  $i$ , $e$  ( $P$ ,Q) is a rank factorization 
> ii) $r(P)=k=r(Q)$ ie,  $P$  is a full column matrix and  $Q$  is a full row matrix
> iii) columns of  $P$  form a basis $\mathcal{C}(A)$
> iv) rows of  $Q$  form a basis of $\mathcal{R}(A)$

`\begin{proof}`
$k\geq r(P)\geq r(PQ)=r(A)$
not to prove the equivalence of condition i to iv

 $i$  $\implies$ ii 
 let  $k=r(A)$
 $k=r(A)=r(PQ)\leq r(P)\leq r(Q)\leq k$
 $\implies r(P)=k, r(Q)=k$
 
 ii $\implies$iii
  $P$  is a full column rank matrix ie, columns of   $P$  are linearly independent 
   $Q$  is a full row rank matrix ie,  $Q$  has right inverse say, $C$.
$\mathcal{C}(PQ)=\mathcal{C}(A)$ 
we need to show $\mathcal{C}(PQ)=\mathcal{C}(P)$
Its easy to see that $\mathcal{C}(PQ)\subseteq \mathcal{C}(P)$
if $Y \in \mathcal{C}(P)\implies \exists \  X  \text{s.t.} PQCX=Y\implies PQ(CX)=Y$
$\implies \mathcal{C}(P)=\mathcal{C}(PQ)=\mathcal{C}(A)$
as  columns of $P$ is linearly independent columns of  $P$  form basis of $\mathcal{C}(P)=\mathcal{C}(P)$   

iii $\implies$ i) easy

complete this by showing ii=>iv and iv<=ii
`\end{proof}`

> [!corollary] 
> If $(P,Q)$ is a rank factorization of A then 
> i) $\mathcal{C}(P)=\mathcal{C}A$
ii) $\mathcal{R}(Q)=\mathcal{R}(A)$
iii) $\mathcal{N}(Q)=\mathcal{N}(A)$

`\begin{proof}`

If $QX=0\implies AQX=0\implies\mathcal{N}(Q)\subseteq\mathcal{N}(A)$
if $AX=0\implies PQX=0\implies P^{-1}PQX=0\implies QX=0\implies\mathcal{N}(A)\subseteq\mathcal{N}(Q)$
`\end{proof}`
> [!theorem] 
> Let A  $B$  be of the same order then 
> $r(A+B)\leq r(A)+r(B)$
> equality holds iff $\mathcal{C}(A)\cap \mathcal{C}(B)=\{0\}$ and $\mathcal{R}(A)\cap \mathcal{R}(B)=\{0\}$ 


`\begin{proof}`
$(A+B)X=AX+BX$
So the column space of $A+B$ is a subspace of the sum of the column space of A and column space of  $B$  

$$
\begin{align}
\mathcal{C}(A+B) & \subseteq \mathcal{C}(A)+\mathcal{C}(B) \\
\dim \mathcal{C}(A+B) & \le \dim\mathcal{C}(A)+\dim\mathcal{C}(B) \\
\implies r(A+B) & \leq \dim \left( \mathcal{C}(A) + \mathcal{C}(B)  \right)  \\
 & = \dim\mathcal{C}(A)+ \dim\mathcal{C}(B)-\dim\left( \mathcal{C}(A)\cap \mathcal{C}(B) \right)  \\
 & \leq r(A)+r(B)
\end{align}
$$
suppose equality holds then $\dim(\mathcal{c}(A)\cap \mathcal{C}(B)=0\implies \mathcal{C}(A)\cap \mathcal{C}(B)=\left\{ 0 \right\})$

$$
\begin{align}
\left(A^{T}+B^{T}\right)X & =A^{T}X+B^{T}X \\
\implies \dim\mathcal{C}(A^{T}+B^{T} \ ) & \leq \dim\mathcal{C}(A^{T} )+\dim\mathcal{C}(B^{T} )-\dim\left( \mathcal{C}(A^{T} )\cap \mathcal{C}(B^{T} ) \right)   \\
 \dim \mathcal{R}(A+B) & = \dim\mathcal{R}(A)+ \dim\mathcal{R}(B)-\dim\left( \mathcal{R}(A)\cap \mathcal{R}(B) \right)  \\

\end{align}
$$
As equality holds 
$$
\begin{align}
r(A+B) & =r(A)+r(B)\\
\implies \dim(\mathcal{R}(A)\cap \mathcal{R}(B)) & =\left\{ 0 \right\}
\end{align}
$$

conversely, let $\mathcal{C}(A)\cap \mathcal{C}(B)=\left\{ {0} \right\}$ and $\mathcal{R}(A)\cap \mathcal{R}(B)=\left\{ {0} \right\}$\
let $r(A)=r$ and $r(B)=s$
if $rs=0$ we are done 
so lets assume  $r,s\geq1$ 
let $(P_{1},Q_{1})$ be a rank factorization of $A$ and $(P_{2},Q_{2})$ that of B

then $A+B=P_{1}Q_{1}+P_{2}Q_{2}$
if $Q=\begin{bmatrix}Q_{1} \\ Q_{2}\end{bmatrix}$ and $P=\left[ P_{1},P_{2} \right]$
then $A+B=PQ$ 
$\mathcal{C}(P_{1})\cap \mathcal{C}(P_{2})=\mathcal{C}(A)\cap \mathcal{C}(B)=\left\{ 0 \right\}$
also columns of $P_{1}$ and $P_{2}$ are linearly independent
columns of  $P$  are linearly independent from ($\mathcal{C}(P_{1})\cap \mathcal{C}(P_{2})=\mathcal{C}(A)\cap \mathcal{C}(B)=\left\{ 0 \right\}$)
so $(P,Q)$ is a rank factorization of $A+B$ and $r(A+B)=r+s=r(A)+r(B)$

`\end{proof}`