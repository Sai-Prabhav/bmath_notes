#1-oct

> [!definition] Rank Factorization of Matrix
Let $A$ be a $m\times n$ matrix of rank $r$ . $A$ Rank factorization of $A$ is a pair of matrices $(P,Q)$ where $P$ is of order $m\times r$ and $Q$ is of order $r\times n$, such that $A=PQ$ 

> [!theorem] 
> Let $A=PQ$ $P$ is $m\times k$ and $Q$ be $k\times n$ then $r(A)\leq k$ also, TFAE
> i)k=r(A), $i$ , $e$ ( $P$ ,Q) is a rank factorization 
> ii) $r(P)=k=r(Q)$ ie, $P$ is a full column matrix and $Q$ is a full row matrix
> iii) columns of $P$ form a basis $\mathcal{C}(A)$
> iv) rows of $Q$ form a basis of $\mathcal{R}(A)$

`\begin{proof}`
$k\geq r(P)\geq r(PQ)=r(A)$
not to prove the equivalence of condition i to iv

 $i$ $\implies$ ii 
 let $k=r(A)$
 $k=r(A)=r(PQ)\leq r(P)\leq r(Q)\leq k$
 $\implies r(P)=k, r(Q)=k$
 
 ii $\implies$iii
 $P$ is a full column rank matrix ie, columns of $P$ are linearly independent 
 $Q$ is a full row rank matrix ie, $Q$ has right inverse say, $C$.
$\mathcal{C}(PQ)=\mathcal{C}(A)$ 
we need to show $\mathcal{C}(PQ)=\mathcal{C}(P)$
Its easy to see that $\mathcal{C}(PQ)\subseteq \mathcal{C}(P)$
if $Y \in \mathcal{C}(P)\implies \exists \ X \text{s.t.} PQCX=Y\implies PQ(CX)=Y$
$\implies \mathcal{C}(P)=\mathcal{C}(PQ)=\mathcal{C}(A)$
as columns of $P$ is linearly independent columns of $P$ form basis of $\mathcal{C}(P)=\mathcal{C}(P)$ 

iii $\implies$ i) easy

Complete this by showing ii=>iv and iv<=ii
`\end{proof}`

> [!corollary] 
> If $(P,Q)$ is a rank factorization of A then 
> i) $\mathcal{C}(P)=\mathcal{C}A$
ii) $\mathcal{R}(Q)=\mathcal{R}(A)$
iii) $\mathcal{N}(Q)=\mathcal{N}(A)$

`\begin{proof}`

If $QX=0\implies AQX=0\implies\mathcal{N}(Q)\subseteq\mathcal{N}(A)$
if $AX=0\implies PQX=0\implies P^{-1}PQX=0\implies QX=0\implies\mathcal{N}(A)\subseteq\mathcal{N}(Q)$
`\end{proof}`
> [!theorem] 
> Let A $B$ be of the same order then 
> $r(A+B)\leq r(A)+r(B)$
> equality holds iff $\mathcal{C}(A)\cap \mathcal{C}(B)=\{0\}$ and $\mathcal{R}(A)\cap \mathcal{R}(B)=\{0\}$ 


`\begin{proof}`
$(A+B)X=AX+BX$
So the column space of $A+B$ is a subspace of the sum of the column space of A and column space of $B$ 

$$
\begin{align}
\mathcal{C}(A+B) & \subseteq \mathcal{C}(A)+\mathcal{C}(B) \\
\dim \mathcal{C}(A+B) & \le \dim\mathcal{C}(A)+\dim\mathcal{C}(B) \\
\implies r(A+B) & \leq \dim \left( \mathcal{C}(A) + \mathcal{C}(B) \right) \\
 & = \dim\mathcal{C}(A)+ \dim\mathcal{C}(B)-\dim\left( \mathcal{C}(A)\cap \mathcal{C}(B) \right) \\
 & \leq r(A)+r(B)
\end{align}
$$
suppose equality holds then $\dim(\mathcal{c}(A)\cap \mathcal{C}(B)=0\implies \mathcal{C}(A)\cap \mathcal{C}(B)=\left\{ 0 \right\})$

$$
\begin{align}
\left(A^{T}+B^{T}\right)X & =A^{T}X+B^{T}X \\
\implies \dim\mathcal{C}(A^{T}+B^{T} \ ) & \leq \dim\mathcal{C}(A^{T} )+\dim\mathcal{C}(B^{T} )-\dim\left( \mathcal{C}(A^{T} )\cap \mathcal{C}(B^{T} ) \right) \\
 \dim \mathcal{R}(A+B) & = \dim\mathcal{R}(A)+ \dim\mathcal{R}(B)-\dim\left( \mathcal{R}(A)\cap \mathcal{R}(B) \right) \\

\end{align}
$$
As equality holds 
$$
\begin{align}
r(A+B) & =r(A)+r(B)\\
\implies \dim(\mathcal{R}(A)\cap \mathcal{R}(B)) & =\left\{ 0 \right\}
\end{align}
$$

Conversely, let $\mathcal{C}(A)\cap \mathcal{C}(B)=\left\{ {0} \right\}$ and $\mathcal{R}(A)\cap \mathcal{R}(B)=\left\{ {0} \right\}$\
Let $r(A)=r$ and $r(B)=s$
if $rs=0$ we are done 
so lets assume $r,s\geq1$ 
let $(P_{1},Q_{1})$ be a rank factorization of $A$ and $(P_{2},Q_{2})$ that of B

then $A+B=P_{1}Q_{1}+P_{2}Q_{2}$
if $Q=\begin{bmatrix}Q_{1} \\ Q_{2}\end{bmatrix}$ and $P=\left[ P_{1},P_{2} \right]$
then $A+B=PQ$ 

Case I if $\mathcal{C}(P_{1})\cap \mathcal{C}(P_{2})=\mathcal{C}(A)\cap \mathcal{C}(B)=\left\{ 0 \right\}$
also columns of $P_{1}$ and $P_{2}$ are linearly independent
columns of $P$ are linearly independent from ($\mathcal{C}(P_{1})\cap \mathcal{C}(P_{2})=\mathcal{C}(A)\cap \mathcal{C}(B)=\left\{ 0 \right\}$)
the $r+s$ columns of $P$ are linearly independent columns of $P$.
They form a basis of $\csp{A+B}$ 
so $(P,Q)$ is a rank factorization of $A+B$ and $r(A+B)=r+s=r(A)+r(B)$

`\end{proof}`
#8-oct

> [!theorem] 
> Let A $B$ be of the same order then 
> $r(A_{1}+A_{2}\dots A_{k})\leq r(A_{1})+r(A_{2})+\dots+r(A_{k})$
> equality holds iff $\rsp{A_{1}}+\dots+\rsp{A_{k}}$ and $\csp{A_{1}}+\dots +\csp{A_{k}}$ is a direct sum

^f2e81d


`\begin{proof}`

If $X\in \csp{A_{1}+A_{2}\dots+A_{k}}$
then $X\in \csp{A_{1}}+\dots+\csp{A_{k}}$
$$
\begin{align}
\implies \dim \csp{A_{1}+A_{2}\dots A_{k}} & \leq \dim(\csp{A_{1}}+\csp{A_{2}}\dots \csp{A_{k}}) \\
& =r(A_{1})+\dots r(A_{k} )
\end{align}
$$
 Suppose equality holds then show that the sum $\csp{A_{1}}+\dots+ \csp{A_{k}}$ is a direct sum 
(question::if Its a equal how to show its a direct sum[[4. Rank Factorization of Matrix#^f2e81d|Theorem 4.5]]) 
Conversely assume that the sum $\csp{A_{1}}+\dots +\csp{A_{k}}$ is a direct sum

Let $r(A_{i})\geq1$ if its less than 1 ie, 0 ignore it
and let $(P_{i},Q_{i})$ be a rank fact of $A_{i},1\leq i\leq k$

let $P=\left[ P_{1},P_{2} \dots P_{k}\right]\qquad Q=\begin{bmatrix}Q_{1} \\ Q_{2} \\ \vdots \\ Q_{k}\end{bmatrix}$ 

$$
\begin{align}
A_{1}+A_{2}+\dots A_{k} & =P_{1}Q_{1}+\dots+P_{k}Q_{k} \\
 & =PQ 
\end{align}
$$
As each of the $P_{i}$ 's are full column rank 
the set of all columns of $P$ is a linearly independent set as the sum $\csp{P_{1}}+\csp{P_{2}}\dots \csp{P_{k}}$ is a direct sum
similarly all rows of $Q$ are linear independent 
Hence $P$ is a full column matrix and $Q$ is a full row matrix hence $(P,Q)$ is a rank fact of $A_{1}+\dots A_{k}$ 
$$
\begin{align}
\implies r(A_{1}+\dots A_{k} )=r(P)=r(A_{1})+\dots+r(A_{k} )
\end{align}
$$



`\end{proof}`

> [!definition] 
> Let $S$ be a subspace of $F^{n}$ and $T$ a compliment of $S$ . An $n\times n$ matrix A is said to be a projector into $S$ along $T$ if $\forall X \in F^{n}$, $AX$ is the projection of $X$ into $S$ along $T$ 

Let $A:F^{n}\to F^{n}$ be a projector into $S$ along T

$\ker A=T , \im A=S$ 

So, elements of $T$ are solutions of a system of finitely many hyper planes passing through origin 

> [!theorem] 
> The following are equivalent For a $n\times n$ matrix A 
> i) A is a projectore
> ii) $A^{2}=A$ ie, $A$ is an idempotent
> iii)$\nsp{A}=\csp{I-A}$
> iv) $r(A)+r(I-A)=n$
> v) $\csp{A}+\csp{I-A}$ is a direct sum


`\begin{proof}`
$i\implies ii$
$F^{n}=S\oplus T$ 
Let $(u_{1},u_{2}\dots u_{k})$ be a basis of $S$ and $(v_{1},v_{2}\dots v_{n-k})$ of T

if 
$$
\begin{align}
X & =(a_{1}u_{1}+\dots+a_{k}u_{k},b_{1}v_1+\dots+b_{n-k}v_{n-k}) \\
AX & =(a_{1}u_{1}+\dots a_{k}u_{k} +0 ) \\
A^{2} X & =A(a_{1}u_{1}+\dots a_{k}u_{k} +0 ) \\
A^{2} X & =AX \\
\so A^{2} & =A
\end{align}
$$
$ii\implies iii$
$\nsp{A}\subseteq \csp{I-A}$
let $X\in \csp{I-A}$ ie, $X=(I-A)Y$
$$
\begin{align}
AX & =A(I-A)Y \\
 & = AY-A^{2} Y \\
 & =0
\end{align}
$$
$iii\implies iv$
$$
\begin{align}
r(A)+ \dim\left( \nsp{A}\right) & =n\ \ \ \text{ From Rank-nullity theorem}\\
r(A+\csp{I-A} & =n \\
r(A)+r(I-A) & =n 
\end{align}
$$
$iv\implies v$

$$
\begin{align}
r(A)+r(I-A) & = r(A+I-A) \text{ as } \csp{A}\cap \csp{I-A } =\left\{ 0 \right\} \ \ \ \text{ from the previous theorem} \\
 \implies r(A)+r(I-A) & =n
\end{align}
$$


$v\implies i$

$$
\begin{align}
X & =\underbrace{ AX }_{ \csp{A} }+(\underbrace{ I-A)X }_{ \csp{I-A } } \text{ in a unique way} \\
 F^{n} & = \csp{A}\oplus \csp{I-A} 
\end{align}
$$
A is the projection of $\csp{A}$ along $\csp{I-A}$ 
`\end{proof}`